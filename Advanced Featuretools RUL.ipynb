{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Remaining Useful Life (advanced)\n",
    "<p style=\"margin:30px\">\n",
    "    <img style=\"display:inline; margin-right:50px\" width=50% src=\"https://www.featuretools.com/wp-content/uploads/2017/12/FeatureLabs-Logo-Tangerine-800.png\" alt=\"Featuretools\" />\n",
    "    <img style=\"display:inline\" width=15% src=\"https://upload.wikimedia.org/wikipedia/commons/e/e5/NASA_logo.svg\" alt=\"NASA\" />\n",
    "</p>\n",
    "\n",
    "This notebook has a more advanced workflow than [the other notebook](Simple%20Featuretools%20RUL%20Demo.ipynb) for predicting Remaining Useful Life (RUL). If you are a new to either this dataset or Featuretools, I would recommend reading the other notebook first.\n",
    "\n",
    "## Highlights\n",
    "* Demonstrate how novel entityset structures improve predictive accuracy\n",
    "* Using TSFresh Primitives from a featuretools [addon](https://docs.featuretools.com/getting_started/install.html#add-ons)\n",
    "* Improve Mean Absolute Error by tuning hyper parameters with [BTB](https://github.com/HDI-Project/BTB)\n",
    "\n",
    "Here is a collection of mean absolute errors from both notebooks. Though we've used averages where possible (denoted by \\*), the randomness in the Random Forest Regressor and how we choose labels from the train data changes the score.\n",
    "\n",
    "|                                 | Train/Validation MAE|  Test MAE|\n",
    "|---------------------------------|--------------------------------|\n",
    "| Median Baseline                 | 72.06*              | 50.66*   |\n",
    "| Simple Featuretools             | 40.92*              | 39.56    |\n",
    "| Advanced: Custom Primitives     | 35.90*              | 28.84    |\n",
    "| Advanced: Hyperparameter Tuning | 34.80*              | 27.85    |\n",
    "\n",
    "\n",
    "# Step 1: Load Data\n",
    "We load in the train data using the same function we used in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import composeml as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "import utils\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with:\n",
      "61249 Recordings\n",
      "249 Engines\n",
      "21 Sensor Measurements\n",
      "3 Operational Settings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_no</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>operational_setting_1</th>\n",
       "      <th>operational_setting_2</th>\n",
       "      <th>operational_setting_3</th>\n",
       "      <th>sensor_measurement_1</th>\n",
       "      <th>sensor_measurement_2</th>\n",
       "      <th>sensor_measurement_3</th>\n",
       "      <th>sensor_measurement_4</th>\n",
       "      <th>sensor_measurement_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_measurement_14</th>\n",
       "      <th>sensor_measurement_15</th>\n",
       "      <th>sensor_measurement_16</th>\n",
       "      <th>sensor_measurement_17</th>\n",
       "      <th>sensor_measurement_18</th>\n",
       "      <th>sensor_measurement_19</th>\n",
       "      <th>sensor_measurement_20</th>\n",
       "      <th>sensor_measurement_21</th>\n",
       "      <th>index</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0049</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.68</td>\n",
       "      <td>1343.43</td>\n",
       "      <td>1112.93</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>8074.83</td>\n",
       "      <td>9.3335</td>\n",
       "      <td>0.02</td>\n",
       "      <td>330</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.62</td>\n",
       "      <td>6.3670</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0020</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>491.19</td>\n",
       "      <td>606.07</td>\n",
       "      <td>1477.61</td>\n",
       "      <td>1237.50</td>\n",
       "      <td>9.35</td>\n",
       "      <td>...</td>\n",
       "      <td>8046.13</td>\n",
       "      <td>9.1913</td>\n",
       "      <td>0.02</td>\n",
       "      <td>361</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.37</td>\n",
       "      <td>14.6552</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-01 00:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0038</td>\n",
       "      <td>0.8409</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.95</td>\n",
       "      <td>1343.12</td>\n",
       "      <td>1117.05</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>8066.62</td>\n",
       "      <td>9.4007</td>\n",
       "      <td>0.02</td>\n",
       "      <td>329</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.48</td>\n",
       "      <td>6.4213</td>\n",
       "      <td>2</td>\n",
       "      <td>2000-01-01 00:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.70</td>\n",
       "      <td>1341.24</td>\n",
       "      <td>1118.03</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>8076.05</td>\n",
       "      <td>9.3369</td>\n",
       "      <td>0.02</td>\n",
       "      <td>328</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.54</td>\n",
       "      <td>6.4176</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-01-01 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25.0063</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>60.0</td>\n",
       "      <td>462.54</td>\n",
       "      <td>536.10</td>\n",
       "      <td>1255.23</td>\n",
       "      <td>1033.59</td>\n",
       "      <td>7.05</td>\n",
       "      <td>...</td>\n",
       "      <td>7865.80</td>\n",
       "      <td>10.8366</td>\n",
       "      <td>0.02</td>\n",
       "      <td>305</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.03</td>\n",
       "      <td>8.6754</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-01-01 00:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       engine_no  time_in_cycles  operational_setting_1  \\\n",
       "index                                                     \n",
       "0              1               1                42.0049   \n",
       "1              1               2                20.0020   \n",
       "2              1               3                42.0038   \n",
       "3              1               4                42.0000   \n",
       "4              1               5                25.0063   \n",
       "\n",
       "       operational_setting_2  operational_setting_3  sensor_measurement_1  \\\n",
       "index                                                                       \n",
       "0                     0.8400                  100.0                445.00   \n",
       "1                     0.7002                  100.0                491.19   \n",
       "2                     0.8409                  100.0                445.00   \n",
       "3                     0.8400                  100.0                445.00   \n",
       "4                     0.6207                   60.0                462.54   \n",
       "\n",
       "       sensor_measurement_2  sensor_measurement_3  sensor_measurement_4  \\\n",
       "index                                                                     \n",
       "0                    549.68               1343.43               1112.93   \n",
       "1                    606.07               1477.61               1237.50   \n",
       "2                    548.95               1343.12               1117.05   \n",
       "3                    548.70               1341.24               1118.03   \n",
       "4                    536.10               1255.23               1033.59   \n",
       "\n",
       "       sensor_measurement_5         ...          sensor_measurement_14  \\\n",
       "index                               ...                                  \n",
       "0                      3.91         ...                        8074.83   \n",
       "1                      9.35         ...                        8046.13   \n",
       "2                      3.91         ...                        8066.62   \n",
       "3                      3.91         ...                        8076.05   \n",
       "4                      7.05         ...                        7865.80   \n",
       "\n",
       "       sensor_measurement_15  sensor_measurement_16  sensor_measurement_17  \\\n",
       "index                                                                        \n",
       "0                     9.3335                   0.02                    330   \n",
       "1                     9.1913                   0.02                    361   \n",
       "2                     9.4007                   0.02                    329   \n",
       "3                     9.3369                   0.02                    328   \n",
       "4                    10.8366                   0.02                    305   \n",
       "\n",
       "       sensor_measurement_18  sensor_measurement_19  sensor_measurement_20  \\\n",
       "index                                                                        \n",
       "0                       2212                 100.00                  10.62   \n",
       "1                       2324                 100.00                  24.37   \n",
       "2                       2212                 100.00                  10.48   \n",
       "3                       2212                 100.00                  10.54   \n",
       "4                       1915                  84.93                  14.03   \n",
       "\n",
       "       sensor_measurement_21  index                time  \n",
       "index                                                    \n",
       "0                     6.3670      0 2000-01-01 00:00:00  \n",
       "1                    14.6552      1 2000-01-01 00:10:00  \n",
       "2                     6.4213      2 2000-01-01 00:20:00  \n",
       "3                     6.4176      3 2000-01-01 00:30:00  \n",
       "4                     8.6754      4 2000-01-01 00:40:00  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'data/train_FD004.txt'\n",
    "data = utils.load_data(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also make cutoff times by using [Compose](https://compose.featurelabs.com) for generating labels on engines that reach at least 100 cycles. For each engine, we generate 10 labels that are spaced 10 cycles apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 00:02 | Remaining: 00:00 | Progress: 100%|██████████| engine_no: 2490/2490 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>engine_no</th>\n",
       "      <th>remaining_useful_life</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01 16:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-01 18:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-01 20:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-01 21:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-01 23:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cutoff_time  engine_no  remaining_useful_life\n",
       "id                                                      \n",
       "0  2000-01-01 16:40:00          1                    220\n",
       "1  2000-01-01 18:20:00          1                    210\n",
       "2  2000-01-01 20:00:00          1                    200\n",
       "3  2000-01-01 21:40:00          1                    190\n",
       "4  2000-01-01 23:20:00          1                    180"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remaining_useful_life(df):\n",
    "    return len(df) - 1\n",
    "\n",
    "lm = cp.LabelMaker(\n",
    "    target_entity='engine_no',\n",
    "    time_index='time',\n",
    "    labeling_function=remaining_useful_life,\n",
    ")\n",
    "\n",
    "label_times = lm.search(\n",
    "    data.sort_values('time'),\n",
    "    num_examples_per_instance=10,\n",
    "    minimum_data=100,\n",
    "    gap=10,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "label_times.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to make 5 sets of cutoff times to use for cross validation by random sampling the labels times we created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>engine_no</th>\n",
       "      <th>remaining_useful_life</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-01 18:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000-01-02 07:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2000-01-03 22:10:00</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2000-01-04 04:50:00</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2000-01-06 11:40:00</td>\n",
       "      <td>3</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cutoff_time  engine_no  remaining_useful_life\n",
       "id                                                      \n",
       "1  2000-01-01 18:20:00          1                    210\n",
       "9  2000-01-02 07:40:00          1                    130\n",
       "10 2000-01-03 22:10:00          2                    198\n",
       "14 2000-01-04 04:50:00          2                    158\n",
       "27 2000-01-06 11:40:00          3                    136"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = 5\n",
    "cutoff_time_list = []\n",
    "\n",
    "for i in range(splits):\n",
    "    sample = label_times.sample(n=249, random_state=i)\n",
    "    sample.sort_index(inplace=True)\n",
    "    cutoff_time_list.append(sample)\n",
    "\n",
    "cutoff_time_list[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do something fancy for our entityset. The values for `operational_setting` 1-3 are continuous but create an implicit relation between different engines. If two engines have a similar `operational_setting`, it could indicate that we should expect the sensor measurements to mean similar things. We make clusters of those settings using [KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) from scikit-learn and make a new entity from the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: Dataset\n",
       "  Entities:\n",
       "    recordings [Rows: 61249, Columns: 29]\n",
       "    engines [Rows: 249, Columns: 2]\n",
       "    settings_clusters [Rows: 50, Columns: 2]\n",
       "  Relationships:\n",
       "    recordings.engine_no -> engines.engine_no\n",
       "    recordings.settings_clusters -> settings_clusters.settings_clusters"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nclusters = 50\n",
    "\n",
    "def make_entityset(data, nclusters, kmeans=None):\n",
    "    X = data[[\n",
    "        'operational_setting_1',\n",
    "        'operational_setting_2',\n",
    "        'operational_setting_3',\n",
    "    ]]\n",
    "\n",
    "    if kmeans is None:\n",
    "        kmeans = KMeans(n_clusters=nclusters).fit(X)\n",
    "\n",
    "    data['settings_clusters'] = kmeans.predict(X)\n",
    "\n",
    "    es = ft.EntitySet('Dataset')\n",
    "\n",
    "    es.entity_from_dataframe(\n",
    "        dataframe=data,\n",
    "        entity_id='recordings',\n",
    "        index='index',\n",
    "        time_index='time',\n",
    "    )\n",
    "\n",
    "    es.normalize_entity(\n",
    "        base_entity_id='recordings',\n",
    "        new_entity_id='engines',\n",
    "        index='engine_no',\n",
    "    )\n",
    "\n",
    "    es.normalize_entity(\n",
    "        base_entity_id='recordings',\n",
    "        new_entity_id='settings_clusters',\n",
    "        index='settings_clusters',\n",
    "    )\n",
    "\n",
    "    return es, kmeans\n",
    "\n",
    "\n",
    "es, kmeans = make_entityset(data, nclusters)\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize EntitySet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Dataset Pages: 1 -->\r\n",
       "<svg width=\"548pt\" height=\"573pt\"\r\n",
       " viewBox=\"0.00 0.00 548.00 573.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 569)\">\r\n",
       "<title>Dataset</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-569 544,-569 544,4 -4,4\"/>\r\n",
       "<!-- recordings -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>recordings</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"165,-98.5 165,-564.5 374,-564.5 374,-98.5 165,-98.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"269.5\" y=\"-549.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">recordings (61249 rows)</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"165,-541.5 374,-541.5 \"/>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-526.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">index : index</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-511.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engine_no : id</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-496.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">time_in_cycles : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-481.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">operational_setting_1 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-466.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">operational_setting_2 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-451.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">operational_setting_3 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-436.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_1 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-421.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_2 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-406.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_3 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-391.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_4 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-376.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_5 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-361.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_6 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-346.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_7 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-331.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_8 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-316.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_9 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-301.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_10 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-286.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_11 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-271.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_12 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-256.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_13 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-241.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_14 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-226.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_15 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-211.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_16 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-196.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_17 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-181.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_18 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-166.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_19 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-151.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_20 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-136.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sensor_measurement_21 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-121.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">time : datetime_time_index</text>\r\n",
       "<text text-anchor=\"start\" x=\"173\" y=\"-106.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">settings_clusters : id</text>\r\n",
       "</g>\r\n",
       "<!-- engines -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>engines</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-61.5 261,-61.5 261,-0.5 0,-0.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"130.5\" y=\"-46.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engines (249 rows)</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-38.5 261,-38.5 \"/>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-23.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engine_no : index</text>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">first_recordings_time : datetime_time_index</text>\r\n",
       "</g>\r\n",
       "<!-- recordings&#45;&gt;engines -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>recordings&#45;&gt;engines</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M213,-98.4381C213,-98.4381 213,-71.5741 213,-71.5741\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.5,-71.574 213,-61.5741 209.5,-71.5741 216.5,-71.574\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"184\" y=\"-73.8061\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engine_no</text>\r\n",
       "</g>\r\n",
       "<!-- settings_clusters -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>settings_clusters</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"279,-0.5 279,-61.5 540,-61.5 540,-0.5 279,-0.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"409.5\" y=\"-46.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">settings_clusters (50 rows)</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"279,-38.5 540,-38.5 \"/>\r\n",
       "<text text-anchor=\"start\" x=\"287\" y=\"-23.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">settings_clusters : index</text>\r\n",
       "<text text-anchor=\"start\" x=\"287\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">first_recordings_time : datetime_time_index</text>\r\n",
       "</g>\r\n",
       "<!-- recordings&#45;&gt;settings_clusters -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>recordings&#45;&gt;settings_clusters</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M326.5,-98.4381C326.5,-98.4381 326.5,-71.5741 326.5,-71.5741\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"330,-71.574 326.5,-61.5741 323,-71.5741 330,-71.574\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"280\" y=\"-73.8061\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">settings_clusters</text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1e8505572b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: DFS and Creating a Model\n",
    "In addition to changing our `EntitySet` structure, we're also going to use the [Complexity](http://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_extraction.html#tsfresh.feature_extraction.feature_calculators.cid_ce) time series primitive from the featuretools [addon](https://docs.featuretools.com/getting_started/install.html#add-ons) of ready-to-use TSFresh Primitives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 304 features\n",
      "Elapsed: 04:20 | Progress: 100%|█████████████████████████████████████████████████████████████\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAST(recordings.index)</th>\n",
       "      <th>LAST(recordings.time_in_cycles)</th>\n",
       "      <th>LAST(recordings.operational_setting_1)</th>\n",
       "      <th>LAST(recordings.operational_setting_2)</th>\n",
       "      <th>LAST(recordings.operational_setting_3)</th>\n",
       "      <th>LAST(recordings.sensor_measurement_1)</th>\n",
       "      <th>LAST(recordings.sensor_measurement_2)</th>\n",
       "      <th>LAST(recordings.sensor_measurement_3)</th>\n",
       "      <th>LAST(recordings.sensor_measurement_4)</th>\n",
       "      <th>LAST(recordings.sensor_measurement_5)</th>\n",
       "      <th>...</th>\n",
       "      <th>CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_13, normalize=False), normalize=False)</th>\n",
       "      <th>CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_14, normalize=False), normalize=False)</th>\n",
       "      <th>CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_15, normalize=False), normalize=False)</th>\n",
       "      <th>CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_16, normalize=False), normalize=False)</th>\n",
       "      <th>CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_17, normalize=False), normalize=False)</th>\n",
       "      <th>CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_18, normalize=False), normalize=False)</th>\n",
       "      <th>CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_19, normalize=False), normalize=False)</th>\n",
       "      <th>CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_20, normalize=False), normalize=False)</th>\n",
       "      <th>CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_21, normalize=False), normalize=False)</th>\n",
       "      <th>remaining_useful_life</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine_no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>111</td>\n",
       "      <td>42.0072</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.90</td>\n",
       "      <td>1341.72</td>\n",
       "      <td>1113.93</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2.827411</td>\n",
       "      <td>53.098096</td>\n",
       "      <td>0.351358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.398212</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.635127</td>\n",
       "      <td>1.157763</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>42.0059</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.92</td>\n",
       "      <td>1346.81</td>\n",
       "      <td>1113.44</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>4.571615</td>\n",
       "      <td>96.835481</td>\n",
       "      <td>0.617748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.707586</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.649306</td>\n",
       "      <td>1.772956</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>421</td>\n",
       "      <td>101</td>\n",
       "      <td>34.9989</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>100.0</td>\n",
       "      <td>449.44</td>\n",
       "      <td>555.49</td>\n",
       "      <td>1359.56</td>\n",
       "      <td>1128.23</td>\n",
       "      <td>5.48</td>\n",
       "      <td>...</td>\n",
       "      <td>3.975543</td>\n",
       "      <td>255.373641</td>\n",
       "      <td>0.923450</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>30.279156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.625500</td>\n",
       "      <td>1.986218</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>461</td>\n",
       "      <td>141</td>\n",
       "      <td>35.0072</td>\n",
       "      <td>0.8403</td>\n",
       "      <td>100.0</td>\n",
       "      <td>449.44</td>\n",
       "      <td>555.80</td>\n",
       "      <td>1362.03</td>\n",
       "      <td>1118.05</td>\n",
       "      <td>5.48</td>\n",
       "      <td>...</td>\n",
       "      <td>4.536202</td>\n",
       "      <td>300.262747</td>\n",
       "      <td>1.100772</td>\n",
       "      <td>0.028284</td>\n",
       "      <td>34.556884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.051232</td>\n",
       "      <td>2.170770</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>790</td>\n",
       "      <td>171</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.13</td>\n",
       "      <td>1587.93</td>\n",
       "      <td>1402.21</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>4.714893</td>\n",
       "      <td>348.550332</td>\n",
       "      <td>1.090390</td>\n",
       "      <td>0.078740</td>\n",
       "      <td>37.594292</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.408281</td>\n",
       "      <td>2.678489</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           LAST(recordings.index)  LAST(recordings.time_in_cycles)  \\\n",
       "engine_no                                                            \n",
       "1                             110                              111   \n",
       "1                             190                              191   \n",
       "2                             421                              101   \n",
       "2                             461                              141   \n",
       "3                             790                              171   \n",
       "\n",
       "           LAST(recordings.operational_setting_1)  \\\n",
       "engine_no                                           \n",
       "1                                         42.0072   \n",
       "1                                         42.0059   \n",
       "2                                         34.9989   \n",
       "2                                         35.0072   \n",
       "3                                          0.0026   \n",
       "\n",
       "           LAST(recordings.operational_setting_2)  \\\n",
       "engine_no                                           \n",
       "1                                          0.8400   \n",
       "1                                          0.8400   \n",
       "2                                          0.8402   \n",
       "2                                          0.8403   \n",
       "3                                          0.0000   \n",
       "\n",
       "           LAST(recordings.operational_setting_3)  \\\n",
       "engine_no                                           \n",
       "1                                           100.0   \n",
       "1                                           100.0   \n",
       "2                                           100.0   \n",
       "2                                           100.0   \n",
       "3                                           100.0   \n",
       "\n",
       "           LAST(recordings.sensor_measurement_1)  \\\n",
       "engine_no                                          \n",
       "1                                         445.00   \n",
       "1                                         445.00   \n",
       "2                                         449.44   \n",
       "2                                         449.44   \n",
       "3                                         518.67   \n",
       "\n",
       "           LAST(recordings.sensor_measurement_2)  \\\n",
       "engine_no                                          \n",
       "1                                         548.90   \n",
       "1                                         548.92   \n",
       "2                                         555.49   \n",
       "2                                         555.80   \n",
       "3                                         642.13   \n",
       "\n",
       "           LAST(recordings.sensor_measurement_3)  \\\n",
       "engine_no                                          \n",
       "1                                        1341.72   \n",
       "1                                        1346.81   \n",
       "2                                        1359.56   \n",
       "2                                        1362.03   \n",
       "3                                        1587.93   \n",
       "\n",
       "           LAST(recordings.sensor_measurement_4)  \\\n",
       "engine_no                                          \n",
       "1                                        1113.93   \n",
       "1                                        1113.44   \n",
       "2                                        1128.23   \n",
       "2                                        1118.05   \n",
       "3                                        1402.21   \n",
       "\n",
       "           LAST(recordings.sensor_measurement_5)          ...            \\\n",
       "engine_no                                                 ...             \n",
       "1                                           3.91          ...             \n",
       "1                                           3.91          ...             \n",
       "2                                           5.48          ...             \n",
       "2                                           5.48          ...             \n",
       "3                                          14.62          ...             \n",
       "\n",
       "           CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_13, normalize=False), normalize=False)  \\\n",
       "engine_no                                                                                                                    \n",
       "1                                                   2.827411                                                                 \n",
       "1                                                   4.571615                                                                 \n",
       "2                                                   3.975543                                                                 \n",
       "2                                                   4.536202                                                                 \n",
       "3                                                   4.714893                                                                 \n",
       "\n",
       "           CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_14, normalize=False), normalize=False)  \\\n",
       "engine_no                                                                                                                    \n",
       "1                                                  53.098096                                                                 \n",
       "1                                                  96.835481                                                                 \n",
       "2                                                 255.373641                                                                 \n",
       "2                                                 300.262747                                                                 \n",
       "3                                                 348.550332                                                                 \n",
       "\n",
       "           CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_15, normalize=False), normalize=False)  \\\n",
       "engine_no                                                                                                                    \n",
       "1                                                   0.351358                                                                 \n",
       "1                                                   0.617748                                                                 \n",
       "2                                                   0.923450                                                                 \n",
       "2                                                   1.100772                                                                 \n",
       "3                                                   1.090390                                                                 \n",
       "\n",
       "           CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_16, normalize=False), normalize=False)  \\\n",
       "engine_no                                                                                                                    \n",
       "1                                                   0.000000                                                                 \n",
       "1                                                   0.000000                                                                 \n",
       "2                                                   0.020000                                                                 \n",
       "2                                                   0.028284                                                                 \n",
       "3                                                   0.078740                                                                 \n",
       "\n",
       "           CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_17, normalize=False), normalize=False)  \\\n",
       "engine_no                                                                                                                    \n",
       "1                                                  22.398212                                                                 \n",
       "1                                                  28.707586                                                                 \n",
       "2                                                  30.279156                                                                 \n",
       "2                                                  34.556884                                                                 \n",
       "3                                                  37.594292                                                                 \n",
       "\n",
       "           CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_18, normalize=False), normalize=False)  \\\n",
       "engine_no                                                                                                                    \n",
       "1                                                          0                                                                 \n",
       "1                                                          0                                                                 \n",
       "2                                                          0                                                                 \n",
       "2                                                          0                                                                 \n",
       "3                                                          0                                                                 \n",
       "\n",
       "           CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_19, normalize=False), normalize=False)  \\\n",
       "engine_no                                                                                                                    \n",
       "1                                                        0.0                                                                 \n",
       "1                                                        0.0                                                                 \n",
       "2                                                        0.0                                                                 \n",
       "2                                                        0.0                                                                 \n",
       "3                                                        0.0                                                                 \n",
       "\n",
       "           CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_20, normalize=False), normalize=False)  \\\n",
       "engine_no                                                                                                                    \n",
       "1                                                   1.635127                                                                 \n",
       "1                                                   2.649306                                                                 \n",
       "2                                                   2.625500                                                                 \n",
       "2                                                   3.051232                                                                 \n",
       "3                                                   4.408281                                                                 \n",
       "\n",
       "           CID_CE(recordings.settings_clusters.CID_CE(recordings.sensor_measurement_21, normalize=False), normalize=False)  \\\n",
       "engine_no                                                                                                                    \n",
       "1                                                   1.157763                                                                 \n",
       "1                                                   1.772956                                                                 \n",
       "2                                                   1.986218                                                                 \n",
       "2                                                   2.170770                                                                 \n",
       "3                                                   2.678489                                                                 \n",
       "\n",
       "           remaining_useful_life  \n",
       "engine_no                         \n",
       "1                            210  \n",
       "1                            130  \n",
       "2                            198  \n",
       "2                            158  \n",
       "3                            136  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from featuretools.tsfresh import CidCe\n",
    "\n",
    "fm, features = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_entity='engines',\n",
    "    agg_primitives=['last', 'max', CidCe(normalize=False)],\n",
    "    trans_primitives=[],\n",
    "    chunk_size=.26,\n",
    "    cutoff_time=cutoff_time_list[0],\n",
    "    max_depth=3,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "fm.to_csv('advanced_fm.csv')\n",
    "fm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build 4 more feature matrices with the same feature set but different cutoff times. That lets us test the pipeline multiple times before using it on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 4/4 [18:58<00:00, 284.56s/it]\n"
     ]
    }
   ],
   "source": [
    "fm_list = [fm]\n",
    "\n",
    "for i in tqdm(range(1, splits)):\n",
    "    es = make_entityset(data, nclusters, kmeans=kmeans)[0]\n",
    "    fm = ft.calculate_feature_matrix(\n",
    "        entityset=es,\n",
    "        features=features,\n",
    "        chunk_size=.26,\n",
    "        cutoff_time=cutoff_time_list[i],\n",
    "    )\n",
    "    fm_list.append(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44.5, 34.7, 38.7, 41.6, 38.7]\n",
      "Average MAE: 39.6, Std: 3.26\n",
      "\n",
      "1: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_13)) [0.095]\n",
      "2: MAX(recordings.sensor_measurement_13) [0.087]\n",
      "3: MAX(recordings.sensor_measurement_11) [0.081]\n",
      "4: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_4)) [0.066]\n",
      "5: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_11)) [0.063]\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def pipeline_for_test(fm_list, hyperparams=None, do_selection=False):\n",
    "    scores = []\n",
    "    regs = []\n",
    "    selectors = []\n",
    "\n",
    "    hyperparams = hyperparams or {\n",
    "        'n_estimators': 100,\n",
    "        'max_feats': 50,\n",
    "        'nfeats': 50,\n",
    "    }\n",
    "\n",
    "    for fm in fm_list:\n",
    "        X = fm.copy().fillna(0)\n",
    "        y = X.pop('remaining_useful_life')\n",
    "\n",
    "        n_estimators = int(hyperparams['n_estimators'])\n",
    "        max_features = int(hyperparams['max_feats'])\n",
    "        max_features = min(max_features, int(hyperparams['nfeats']))\n",
    "        reg = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "        if do_selection:\n",
    "            reg2 = RandomForestRegressor(n_estimators=10, n_jobs=3)\n",
    "            selector = RFE(reg2, int(hyperparams['nfeats']), step=25)\n",
    "            selector.fit(X_train, y_train)\n",
    "            X_train = selector.transform(X_train)\n",
    "            X_test = selector.transform(X_test)\n",
    "            selectors.append(selector)\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "        regs.append(reg)\n",
    "\n",
    "        preds = reg.predict(X_test)\n",
    "        mae = mean_absolute_error(preds, y_test)\n",
    "        scores.append(mae)\n",
    "\n",
    "    return scores, regs, selectors\n",
    "\n",
    "\n",
    "scores, regs, selectors = pipeline_for_test(fm_list)\n",
    "print([float('{:.1f}'.format(score)) for score in scores])\n",
    "\n",
    "mean, std = np.mean(scores), np.std(scores)\n",
    "info = 'Average MAE: {:.1f}, Std: {:.2f}\\n'\n",
    "print(info.format(mean, std))\n",
    "\n",
    "most_imp_feats = utils.feature_importances(fm_list[0], regs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with:\n",
      "41214 Recordings\n",
      "248 Engines\n",
      "21 Sensor Measurements\n",
      "3 Operational Settings\n",
      "Elapsed: 00:06 | Progress: 100%|█████████████████████████████████████████████████████████████\n",
      "Mean Abs Error: 28.08\n"
     ]
    }
   ],
   "source": [
    "data_test = utils.load_data('data/test_FD004.txt')\n",
    "\n",
    "es_test, _ = make_entityset(\n",
    "    data_test,\n",
    "    nclusters,\n",
    "    kmeans=kmeans,\n",
    ")\n",
    "\n",
    "fm_test = ft.calculate_feature_matrix(\n",
    "    entityset=es_test,\n",
    "    features=features,\n",
    "    verbose=True,\n",
    "    chunk_size=.26,\n",
    ")\n",
    "\n",
    "X = fm_test.copy().fillna(0)\n",
    "\n",
    "y = pd.read_csv(\n",
    "    'data/RUL_FD004.txt',\n",
    "    sep=' ',\n",
    "    header=None,\n",
    "    names=['remaining_useful_life'],\n",
    "    index_col=False,\n",
    ")\n",
    "\n",
    "preds = regs[0].predict(X)\n",
    "mae = mean_absolute_error(preds, y)\n",
    "print('Mean Abs Error: {:.2f}'.format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Feature Selection and Scoring\n",
    "Here, we'll use [Recursive Feature Elimination](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html). In order to set ourselves up for later optimization, we're going to write a generic `pipeline` function which takes in a set of hyperparameters and returns a score. Our pipeline will first run `RFE` and then split the remaining data for scoring by a `RandomForestRegressor`. We're going to pass in a list of hyperparameters, which we will tune later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can use that selector and regressor to score the test values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Hyperparameter Tuning\n",
    "Because of the way we set up our pipeline, we can use a Gaussian Process to tune the hyperparameters. We will use [BTB](https://github.com/HDI-Project/BTB) from the [HDI Project](https://github.com/HDI-Project). This will search through the hyperparameters `n_estimators` and `max_feats` for RandomForest, and the number of features for RFE to find the hyperparameter set that has the best average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_est, max_feats, nfeats]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                 | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. {'n_estimators': 191, 'max_feats': 26, 'nfeats': 27} -- Average MAE: 38.9, Std: 3.09\n",
      "Raw: [33.7, 37.6, 42.9, 40.8, 39.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████▋                                                   | 3/30 [00:58<08:35, 19.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. {'n_estimators': 36, 'max_feats': 47, 'nfeats': 30} -- Average MAE: 34.2, Std: 1.29\n",
      "Raw: [36.4, 34.1, 34.5, 33.5, 32.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 30/30 [09:13<00:00, 18.44s/it]\n"
     ]
    }
   ],
   "source": [
    "from btb import HyperParameter, ParamTypes\n",
    "from btb.tuning import GP\n",
    "\n",
    "\n",
    "def run_btb(fm_list, n=30, best=45):\n",
    "    hyperparam_ranges = [\n",
    "        ('n_estimators', HyperParameter(ParamTypes.INT, [10, 200])),\n",
    "        ('max_feats', HyperParameter(ParamTypes.INT, [5, 50])),\n",
    "        ('nfeats', HyperParameter(ParamTypes.INT, [10, 70])),\n",
    "    ]\n",
    "\n",
    "    tuner = GP(hyperparam_ranges)\n",
    "    shape = (n, len(hyperparam_ranges))\n",
    "    tested_parameters = np.zeros(shape, dtype=object)\n",
    "    scores = []\n",
    "\n",
    "    print('[n_est, max_feats, nfeats]')\n",
    "\n",
    "    best_hyperparams = None\n",
    "    best_sel = None\n",
    "    best_reg = None\n",
    "\n",
    "    for i in tqdm(range(n)):\n",
    "        hyperparams = tuner.propose()\n",
    "\n",
    "        cvscores, regs, selectors = pipeline_for_test(\n",
    "            fm_list,\n",
    "            hyperparams=hyperparams,\n",
    "            do_selection=True,\n",
    "        )\n",
    "\n",
    "        bound = np.mean(cvscores)\n",
    "        tested_parameters[i, :] = hyperparams\n",
    "        tuner.add(hyperparams, -np.mean(cvscores))\n",
    "\n",
    "        if np.mean(cvscores) + np.std(cvscores) < best:\n",
    "            best = np.mean(cvscores)\n",
    "            best_hyperparams = hyperparams\n",
    "            best_reg = regs[0]\n",
    "            best_sel = selectors[0]\n",
    "\n",
    "            info = '{}. {} -- Average MAE: {:.1f}, Std: {:.2f}'\n",
    "            mean, std = np.mean(cvscores), np.std(cvscores)\n",
    "            print(info.format(i, best_hyperparams, mean, std))\n",
    "            print('Raw: {}'.format([float('{:.1f}'.format(s)) for s in cvscores]))\n",
    "\n",
    "    return best_hyperparams, (best_sel, best_reg)\n",
    "\n",
    "\n",
    "best_hyperparams, best_pipeline = run_btb(fm_list, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Abs Error on Test: 32.77\n",
      "1: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_13)) [0.207]\n",
      "2: MAX(recordings.sensor_measurement_13) [0.161]\n",
      "3: MAX(recordings.sensor_measurement_15) [0.104]\n",
      "4: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_4)) [0.103]\n",
      "5: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_15)) [0.048]\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = fm_test.copy().fillna(0)\n",
    "\n",
    "y = pd.read_csv(\n",
    "    'data/RUL_FD004.txt',\n",
    "    sep=' ',\n",
    "    header=None,\n",
    "    names=['remaining_useful_life'],\n",
    "    index_col=False,\n",
    ")\n",
    "\n",
    "preds = best_pipeline[1].predict(best_pipeline[0].transform(X))\n",
    "score = mean_absolute_error(preds, y)\n",
    "print('Mean Abs Error on Test: {:.2f}'.format(score))\n",
    "\n",
    "most_imp_feats = utils.feature_importances(\n",
    "    X.iloc[:, best_pipeline[0].support_],\n",
    "    best_pipeline[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Averaging old scores\n",
    "To make a fair comparison between the previous notebook and this one, we should average scores where possible. The work in this section is exactly the work in the previous notebook plus some code for taking the average in the validation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 304 features\n",
      "Elapsed: 04:11 | Progress: 100%|█████████████████████████████████████████████████████████████\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 4/4 [19:49<00:00, 297.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41.8, 31.6, 29.7, 35.9, 33.7]\n",
      "Average MAE: 34.56, Std: 4.20\n",
      "\n",
      "[66.9, 54.7, 48.2, 50.3, 56.1]\n",
      "Baseline by Median MAE: 55.23, Std: 6.52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from featuretools.primitives import Min\n",
    "\n",
    "old_fm, features = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_entity='engines',\n",
    "    agg_primitives=['last', 'max', 'min'],\n",
    "    trans_primitives=[],\n",
    "    cutoff_time=cutoff_time_list[0],\n",
    "    max_depth=3,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "old_fm_list = [old_fm]\n",
    "\n",
    "for i in tqdm(range(1, splits)):\n",
    "    es = make_entityset(data, nclusters, kmeans=kmeans)[0]\n",
    "    old_fm = ft.calculate_feature_matrix(\n",
    "        entityset=es,\n",
    "        features=features,\n",
    "        cutoff_time=cutoff_time_list[i],\n",
    "    )\n",
    "    old_fm_list.append(fm)\n",
    "\n",
    "old_scores = []\n",
    "median_scores = []\n",
    "\n",
    "for fm in old_fm_list:\n",
    "    X = fm.copy().fillna(0)\n",
    "    y = X.pop('remaining_useful_life')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    reg = RandomForestRegressor(n_estimators=10)\n",
    "    reg.fit(X_train, y_train)\n",
    "    preds = reg.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(preds, y_test)\n",
    "    old_scores.append(mae)\n",
    "\n",
    "    medianpredict = [np.median(y_train) for _ in y_test]\n",
    "    mae = mean_absolute_error(medianpredict, y_test)\n",
    "    median_scores.append(mae)\n",
    "\n",
    "print([float('{:.1f}'.format(score)) for score in old_scores])\n",
    "mean, std = np.mean(old_scores), np.std(old_scores)\n",
    "info = 'Average MAE: {:.2f}, Std: {:.2f}\\n'\n",
    "print(info.format(mean, std))\n",
    "\n",
    "print([float('{:.1f}'.format(score)) for score in median_scores])\n",
    "mean, std = np.mean(median_scores), np.std(median_scores)\n",
    "info = 'Baseline by Median MAE: {:.2f}, Std: {:.2f}\\n'\n",
    "print(info.format(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.4, 48.1, 47.4, 46.7, 46.5]\n",
      "Baseline by Median MAE: 47.18, Std: 0.58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv(\n",
    "    'data/RUL_FD004.txt',\n",
    "    sep=' ',\n",
    "    header=None,\n",
    "    names=['remaining_useful_life'],\n",
    "    index_col=False,\n",
    ")\n",
    "\n",
    "median_scores_2 = []\n",
    "\n",
    "for ct in cutoff_time_list:\n",
    "    medianpredict2 = [np.median(ct['remaining_useful_life'].values) for _ in y.values]\n",
    "    mae = mean_absolute_error(medianpredict2, y)\n",
    "    median_scores_2.append(mae)\n",
    "\n",
    "print([float('{:.1f}'.format(score)) for score in median_scores_2])\n",
    "mean, std = np.mean(median_scores_2), np.std(median_scores_2)\n",
    "info = 'Baseline by Median MAE: {:.2f}, Std: {:.2f}\\n'\n",
    "print(info.format(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output files\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "fm.to_csv('output/advanced_train_feature_matrix.csv')\n",
    "cutoff_time_list[0].to_csv('output/advanced_train_label_times.csv')\n",
    "fm_test.to_csv('output/advanced_test_feature_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <img src=\"https://www.featurelabs.com/wp-content/uploads/2017/12/logo.png\" alt=\"Featuretools\" />\n",
    "</p>\n",
    "\n",
    "Featuretools was created by the developers at [Feature Labs](https://www.featurelabs.com/). If building impactful data science pipelines is important to you or your business, please [get in touch](https://www.featurelabs.com/contact)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

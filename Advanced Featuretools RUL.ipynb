{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Remaining Useful Life (advanced)\n",
    "<p style=\"margin:30px\">\n",
    "    <img style=\"display:inline; margin-right:50px\" width=50% src=\"https://www.featuretools.com/wp-content/uploads/2017/12/FeatureLabs-Logo-Tangerine-800.png\" alt=\"Featuretools\" />\n",
    "    <img style=\"display:inline\" width=15% src=\"https://upload.wikimedia.org/wikipedia/commons/e/e5/NASA_logo.svg\" alt=\"NASA\" />\n",
    "</p>\n",
    "\n",
    "This notebook has a more advanced workflow than [the other notebook](Simple%20Featuretools%20RUL%20Demo.ipynb) for predicting Remaining Useful Life (RUL). If you are a new to either this dataset or Featuretools, I would recommend reading the other notebook first. \n",
    "\n",
    "## Highlights\n",
    "* Demonstrate how novel entityset structures improve predictive accuracy\n",
    "* Build custom primitives using time-series functions from [tsfresh](https://github.com/blue-yonder/tsfresh)\n",
    "* Improve Mean Absolute Error by tuning hyper parameters with [BTB](https://github.com/HDI-Project/BTB)\n",
    "\n",
    "Here is a collection of mean absolute errors from both notebooks. Though we've used averages where possible (denoted by \\*), the randomness in the Random Forest Regressor and how we choose labels from the train data changes the score.\n",
    "\n",
    "|                                 | Train/Validation MAE|  Test MAE|\n",
    "|---------------------------------|--------------------------------|\n",
    "| Median Baseline                 | 65.81*              | 50.93*   |\n",
    "| Simple Featuretools             | 38.41*              | 39.56    |\n",
    "| Advanced: Custom Primitives     | 35.30*              | 32.38    |\n",
    "| Advanced: Hyperparameter Tuning | 31.10*              | 28.60    |\n",
    "\n",
    "\n",
    "# Step 1: Load Data\n",
    "We load in the train data using the same function we used in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using previously downloaded data\n",
      "Loaded data with:\n",
      "61249 Recordings\n",
      "249 Engines\n",
      "21 Sensor Measurements\n",
      "3 Operational Settings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_no</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>operational_setting_1</th>\n",
       "      <th>operational_setting_2</th>\n",
       "      <th>operational_setting_3</th>\n",
       "      <th>sensor_measurement_1</th>\n",
       "      <th>sensor_measurement_2</th>\n",
       "      <th>sensor_measurement_3</th>\n",
       "      <th>sensor_measurement_4</th>\n",
       "      <th>sensor_measurement_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_measurement_14</th>\n",
       "      <th>sensor_measurement_15</th>\n",
       "      <th>sensor_measurement_16</th>\n",
       "      <th>sensor_measurement_17</th>\n",
       "      <th>sensor_measurement_18</th>\n",
       "      <th>sensor_measurement_19</th>\n",
       "      <th>sensor_measurement_20</th>\n",
       "      <th>sensor_measurement_21</th>\n",
       "      <th>index</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0049</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.68</td>\n",
       "      <td>1343.43</td>\n",
       "      <td>1112.93</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>8074.83</td>\n",
       "      <td>9.3335</td>\n",
       "      <td>0.02</td>\n",
       "      <td>330</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.62</td>\n",
       "      <td>6.3670</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0020</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>491.19</td>\n",
       "      <td>606.07</td>\n",
       "      <td>1477.61</td>\n",
       "      <td>1237.50</td>\n",
       "      <td>9.35</td>\n",
       "      <td>...</td>\n",
       "      <td>8046.13</td>\n",
       "      <td>9.1913</td>\n",
       "      <td>0.02</td>\n",
       "      <td>361</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.37</td>\n",
       "      <td>14.6552</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-01 00:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0038</td>\n",
       "      <td>0.8409</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.95</td>\n",
       "      <td>1343.12</td>\n",
       "      <td>1117.05</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>8066.62</td>\n",
       "      <td>9.4007</td>\n",
       "      <td>0.02</td>\n",
       "      <td>329</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.48</td>\n",
       "      <td>6.4213</td>\n",
       "      <td>2</td>\n",
       "      <td>2000-01-01 00:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.70</td>\n",
       "      <td>1341.24</td>\n",
       "      <td>1118.03</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>8076.05</td>\n",
       "      <td>9.3369</td>\n",
       "      <td>0.02</td>\n",
       "      <td>328</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.54</td>\n",
       "      <td>6.4176</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-01-01 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25.0063</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>60.0</td>\n",
       "      <td>462.54</td>\n",
       "      <td>536.10</td>\n",
       "      <td>1255.23</td>\n",
       "      <td>1033.59</td>\n",
       "      <td>7.05</td>\n",
       "      <td>...</td>\n",
       "      <td>7865.80</td>\n",
       "      <td>10.8366</td>\n",
       "      <td>0.02</td>\n",
       "      <td>305</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.03</td>\n",
       "      <td>8.6754</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-01-01 00:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       engine_no  time_in_cycles  operational_setting_1  \\\n",
       "index                                                     \n",
       "0              1               1                42.0049   \n",
       "1              1               2                20.0020   \n",
       "2              1               3                42.0038   \n",
       "3              1               4                42.0000   \n",
       "4              1               5                25.0063   \n",
       "\n",
       "       operational_setting_2  operational_setting_3  sensor_measurement_1  \\\n",
       "index                                                                       \n",
       "0                     0.8400                  100.0                445.00   \n",
       "1                     0.7002                  100.0                491.19   \n",
       "2                     0.8409                  100.0                445.00   \n",
       "3                     0.8400                  100.0                445.00   \n",
       "4                     0.6207                   60.0                462.54   \n",
       "\n",
       "       sensor_measurement_2  sensor_measurement_3  sensor_measurement_4  \\\n",
       "index                                                                     \n",
       "0                    549.68               1343.43               1112.93   \n",
       "1                    606.07               1477.61               1237.50   \n",
       "2                    548.95               1343.12               1117.05   \n",
       "3                    548.70               1341.24               1118.03   \n",
       "4                    536.10               1255.23               1033.59   \n",
       "\n",
       "       sensor_measurement_5         ...          sensor_measurement_14  \\\n",
       "index                               ...                                  \n",
       "0                      3.91         ...                        8074.83   \n",
       "1                      9.35         ...                        8046.13   \n",
       "2                      3.91         ...                        8066.62   \n",
       "3                      3.91         ...                        8076.05   \n",
       "4                      7.05         ...                        7865.80   \n",
       "\n",
       "       sensor_measurement_15  sensor_measurement_16  sensor_measurement_17  \\\n",
       "index                                                                        \n",
       "0                     9.3335                   0.02                    330   \n",
       "1                     9.1913                   0.02                    361   \n",
       "2                     9.4007                   0.02                    329   \n",
       "3                     9.3369                   0.02                    328   \n",
       "4                    10.8366                   0.02                    305   \n",
       "\n",
       "       sensor_measurement_18  sensor_measurement_19  sensor_measurement_20  \\\n",
       "index                                                                        \n",
       "0                       2212                 100.00                  10.62   \n",
       "1                       2324                 100.00                  24.37   \n",
       "2                       2212                 100.00                  10.48   \n",
       "3                       2212                 100.00                  10.54   \n",
       "4                       1915                  84.93                  14.03   \n",
       "\n",
       "       sensor_measurement_21  index                time  \n",
       "index                                                    \n",
       "0                     6.3670      0 2000-01-01 00:00:00  \n",
       "1                    14.6552      1 2000-01-01 00:10:00  \n",
       "2                     6.4213      2 2000-01-01 00:20:00  \n",
       "3                     6.4176      3 2000-01-01 00:30:00  \n",
       "4                     8.6754      4 2000-01-01 00:40:00  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "import utils\n",
    "\n",
    "utils.download_data()\n",
    "data_path = 'data/train_FD004.txt'\n",
    "data = utils.load_data(data_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also make cutoff times by selecting a random cutoff time from the life of each engine. We're going to make 5 sets of cutoff times to use for cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_no</th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-03 00:00:00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2000-01-03 16:50:00</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2000-01-06 06:10:00</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2000-01-07 16:20:00</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2000-01-09 16:10:00</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       engine_no         cutoff_time  RUL\n",
       "index                                    \n",
       "1              1 2000-01-03 00:00:00   32\n",
       "2              2 2000-01-03 16:50:00  230\n",
       "3              3 2000-01-06 06:10:00  169\n",
       "4              4 2000-01-07 16:20:00  238\n",
       "5              5 2000-01-09 16:10:00  144"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "splits = 5\n",
    "cutoff_time_list = []\n",
    "\n",
    "for i in tqdm(range(splits)):\n",
    "    cutoff_time_list.append(utils.make_cutoff_times(data))\n",
    "\n",
    "cutoff_time_list[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do something fancy for our entityset. The values for `operational_setting` 1-3 are continuous but create an implicit relation between different engines. If two engines have a similar `operational_setting`, it could indicate that we should expect the sensor measurements to mean similar things. We make clusters of those settings using [KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) from scikit-learn and make a new entity from the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: Dataset\n",
       "  Entities:\n",
       "    recordings (shape = [61249, 29])\n",
       "    settings_clusters (shape = [50, 2])\n",
       "    engines (shape = [249, 2])\n",
       "  Relationships:\n",
       "    recordings.engine_no -> engines.engine_no\n",
       "    recordings.settings_clusters -> settings_clusters.settings_clusters"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "nclusters = 50\n",
    "\n",
    "def make_entityset(data, nclusters, kmeans=None):\n",
    "    X = data[['operational_setting_1', 'operational_setting_2', 'operational_setting_3']]\n",
    "    if kmeans:\n",
    "        kmeans=kmeans\n",
    "    else:\n",
    "        kmeans = KMeans(n_clusters=nclusters).fit(X)\n",
    "    data['settings_clusters'] = kmeans.predict(X)\n",
    "    \n",
    "    es = ft.EntitySet('Dataset')\n",
    "    es.entity_from_dataframe(dataframe=data,\n",
    "                             entity_id='recordings',\n",
    "                             index='index',\n",
    "                             time_index='time')\n",
    "\n",
    "    es.normalize_entity(base_entity_id='recordings', \n",
    "                        new_entity_id='engines',\n",
    "                        index='engine_no')\n",
    "    \n",
    "    es.normalize_entity(base_entity_id='recordings', \n",
    "                        new_entity_id='settings_clusters',\n",
    "                        index='settings_clusters')\n",
    "    \n",
    "    return es, kmeans\n",
    "es, kmeans = make_entityset(data, nclusters)\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: DFS and Creating a Model\n",
    "In addition to changing our `EntitySet` structure, we're also going to use the [Complexity](http://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_extraction.html#tsfresh.feature_extraction.feature_calculators.cid_ce) time series primitive from the package [tsfresh](https://github.com/blue-yonder/tsfresh). Any function that takes in a pandas `Series` and outputs a float can be converted into an aggregation primitive using the `make_agg_primitive` function as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 302 features\n",
      "\r",
      "Elapsed: 00:00 | Remaining: ? | Progress:   0%|          | Calculated: 0/4 chunks"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/featurelabs07/homeenv/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 02:26 | Remaining: 00:00 | Progress: 100%|██████████| Calculated: 4/4 chunks\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPLEXITY(recordings.sensor_measurement_15)</th>\n",
       "      <th>MAX(recordings.sensor_measurement_18)</th>\n",
       "      <th>COMPLEXITY(recordings.sensor_measurement_10)</th>\n",
       "      <th>MAX(recordings.sensor_measurement_14)</th>\n",
       "      <th>MAX(recordings.sensor_measurement_6)</th>\n",
       "      <th>LAST(recordings.sensor_measurement_12)</th>\n",
       "      <th>LAST(recordings.sensor_measurement_19)</th>\n",
       "      <th>COMPLEXITY(recordings.operational_setting_3)</th>\n",
       "      <th>COMPLEXITY(recordings.time_in_cycles)</th>\n",
       "      <th>LAST(recordings.sensor_measurement_16)</th>\n",
       "      <th>...</th>\n",
       "      <th>MAX(recordings.settings_clusters.COMPLEXITY(recordings.sensor_measurement_17))</th>\n",
       "      <th>LAST(recordings.settings_clusters.COMPLEXITY(recordings.operational_setting_1))</th>\n",
       "      <th>MAX(recordings.settings_clusters.COMPLEXITY(recordings.sensor_measurement_15))</th>\n",
       "      <th>COMPLEXITY(recordings.settings_clusters.COMPLEXITY(recordings.sensor_measurement_7))</th>\n",
       "      <th>MAX(recordings.settings_clusters.COMPLEXITY(recordings.sensor_measurement_5))</th>\n",
       "      <th>LAST(recordings.settings_clusters.COMPLEXITY(recordings.sensor_measurement_6))</th>\n",
       "      <th>COMPLEXITY(recordings.settings_clusters.COMPLEXITY(recordings.sensor_measurement_12))</th>\n",
       "      <th>COMPLEXITY(recordings.settings_clusters.MAX(recordings.sensor_measurement_3))</th>\n",
       "      <th>LAST(recordings.settings_clusters.LAST(recordings.operational_setting_1))</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine_no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.371821</td>\n",
       "      <td>2388</td>\n",
       "      <td>3.026780</td>\n",
       "      <td>8161.33</td>\n",
       "      <td>21.59</td>\n",
       "      <td>133.09</td>\n",
       "      <td>100.00</td>\n",
       "      <td>357.770876</td>\n",
       "      <td>16.970563</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.483315</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.143753</td>\n",
       "      <td>30.581479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>32.935223</td>\n",
       "      <td>2529.860061</td>\n",
       "      <td>41.9986</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.632125</td>\n",
       "      <td>2388</td>\n",
       "      <td>1.482228</td>\n",
       "      <td>8136.96</td>\n",
       "      <td>21.61</td>\n",
       "      <td>522.03</td>\n",
       "      <td>100.00</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>8.246211</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>9.165151</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.315808</td>\n",
       "      <td>48.147245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036056</td>\n",
       "      <td>47.516567</td>\n",
       "      <td>1194.615874</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.168354</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.347637</td>\n",
       "      <td>8147.30</td>\n",
       "      <td>21.60</td>\n",
       "      <td>164.92</td>\n",
       "      <td>84.93</td>\n",
       "      <td>268.328157</td>\n",
       "      <td>11.704700</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>10.770330</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.375160</td>\n",
       "      <td>66.223187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043589</td>\n",
       "      <td>68.897736</td>\n",
       "      <td>1923.856686</td>\n",
       "      <td>24.9990</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.163799</td>\n",
       "      <td>2388</td>\n",
       "      <td>1.129734</td>\n",
       "      <td>8146.95</td>\n",
       "      <td>21.61</td>\n",
       "      <td>371.65</td>\n",
       "      <td>100.00</td>\n",
       "      <td>138.564065</td>\n",
       "      <td>5.916080</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.435339</td>\n",
       "      <td>44.466471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>46.188364</td>\n",
       "      <td>1062.343931</td>\n",
       "      <td>10.0028</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.366761</td>\n",
       "      <td>2388</td>\n",
       "      <td>1.293136</td>\n",
       "      <td>8126.22</td>\n",
       "      <td>21.61</td>\n",
       "      <td>164.36</td>\n",
       "      <td>84.93</td>\n",
       "      <td>132.664992</td>\n",
       "      <td>6.928203</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>12.409674</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.440665</td>\n",
       "      <td>51.440170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043589</td>\n",
       "      <td>51.280932</td>\n",
       "      <td>1081.969011</td>\n",
       "      <td>25.0067</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           COMPLEXITY(recordings.sensor_measurement_15)  \\\n",
       "engine_no                                                 \n",
       "1                                             18.371821   \n",
       "2                                              8.632125   \n",
       "3                                             14.168354   \n",
       "4                                              7.163799   \n",
       "5                                              7.366761   \n",
       "\n",
       "           MAX(recordings.sensor_measurement_18)  \\\n",
       "engine_no                                          \n",
       "1                                           2388   \n",
       "2                                           2388   \n",
       "3                                           2388   \n",
       "4                                           2388   \n",
       "5                                           2388   \n",
       "\n",
       "           COMPLEXITY(recordings.sensor_measurement_10)  \\\n",
       "engine_no                                                 \n",
       "1                                              3.026780   \n",
       "2                                              1.482228   \n",
       "3                                              2.347637   \n",
       "4                                              1.129734   \n",
       "5                                              1.293136   \n",
       "\n",
       "           MAX(recordings.sensor_measurement_14)  \\\n",
       "engine_no                                          \n",
       "1                                        8161.33   \n",
       "2                                        8136.96   \n",
       "3                                        8147.30   \n",
       "4                                        8146.95   \n",
       "5                                        8126.22   \n",
       "\n",
       "           MAX(recordings.sensor_measurement_6)  \\\n",
       "engine_no                                         \n",
       "1                                         21.59   \n",
       "2                                         21.61   \n",
       "3                                         21.60   \n",
       "4                                         21.61   \n",
       "5                                         21.61   \n",
       "\n",
       "           LAST(recordings.sensor_measurement_12)  \\\n",
       "engine_no                                           \n",
       "1                                          133.09   \n",
       "2                                          522.03   \n",
       "3                                          164.92   \n",
       "4                                          371.65   \n",
       "5                                          164.36   \n",
       "\n",
       "           LAST(recordings.sensor_measurement_19)  \\\n",
       "engine_no                                           \n",
       "1                                          100.00   \n",
       "2                                          100.00   \n",
       "3                                           84.93   \n",
       "4                                          100.00   \n",
       "5                                           84.93   \n",
       "\n",
       "           COMPLEXITY(recordings.operational_setting_3)  \\\n",
       "engine_no                                                 \n",
       "1                                            357.770876   \n",
       "2                                            160.000000   \n",
       "3                                            268.328157   \n",
       "4                                            138.564065   \n",
       "5                                            132.664992   \n",
       "\n",
       "           COMPLEXITY(recordings.time_in_cycles)  \\\n",
       "engine_no                                          \n",
       "1                                      16.970563   \n",
       "2                                       8.246211   \n",
       "3                                      11.704700   \n",
       "4                                       5.916080   \n",
       "5                                       6.928203   \n",
       "\n",
       "           LAST(recordings.sensor_measurement_16) ...   \\\n",
       "engine_no                                         ...    \n",
       "1                                            0.02 ...    \n",
       "2                                            0.03 ...    \n",
       "3                                            0.02 ...    \n",
       "4                                            0.03 ...    \n",
       "5                                            0.02 ...    \n",
       "\n",
       "           MAX(recordings.settings_clusters.COMPLEXITY(recordings.sensor_measurement_17))  \\\n",
       "engine_no                                                                                   \n",
       "1                                                   7.483315                                \n",
       "2                                                   9.165151                                \n",
       "3                                                  10.770330                                \n",
       "4                                                  12.000000                                \n",
       "5                                                  12.409674                                \n",
       "\n",
       "           LAST(recordings.settings_clusters.COMPLEXITY(recordings.operational_setting_1))  \\\n",
       "engine_no                                                                                    \n",
       "1                                                   0.002256                                 \n",
       "2                                                   0.001349                                 \n",
       "3                                                   0.001995                                 \n",
       "4                                                   0.003169                                 \n",
       "5                                                   0.003345                                 \n",
       "\n",
       "           MAX(recordings.settings_clusters.COMPLEXITY(recordings.sensor_measurement_15))  \\\n",
       "engine_no                                                                                   \n",
       "1                                                   0.143753                                \n",
       "2                                                   0.315808                                \n",
       "3                                                   0.375160                                \n",
       "4                                                   0.435339                                \n",
       "5                                                   0.440665                                \n",
       "\n",
       "           COMPLEXITY(recordings.settings_clusters.COMPLEXITY(recordings.sensor_measurement_7))  \\\n",
       "engine_no                                                                                         \n",
       "1                                                  30.581479                                      \n",
       "2                                                  48.147245                                      \n",
       "3                                                  66.223187                                      \n",
       "4                                                  44.466471                                      \n",
       "5                                                  51.440170                                      \n",
       "\n",
       "           MAX(recordings.settings_clusters.COMPLEXITY(recordings.sensor_measurement_5))  \\\n",
       "engine_no                                                                                  \n",
       "1                                                        0.0                               \n",
       "2                                                        0.0                               \n",
       "3                                                        0.0                               \n",
       "4                                                        0.0                               \n",
       "5                                                        0.0                               \n",
       "\n",
       "           LAST(recordings.settings_clusters.COMPLEXITY(recordings.sensor_measurement_6))  \\\n",
       "engine_no                                                                                   \n",
       "1                                                   0.020000                                \n",
       "2                                                   0.036056                                \n",
       "3                                                   0.043589                                \n",
       "4                                                   0.042426                                \n",
       "5                                                   0.043589                                \n",
       "\n",
       "           COMPLEXITY(recordings.settings_clusters.COMPLEXITY(recordings.sensor_measurement_12))  \\\n",
       "engine_no                                                                                          \n",
       "1                                                  32.935223                                       \n",
       "2                                                  47.516567                                       \n",
       "3                                                  68.897736                                       \n",
       "4                                                  46.188364                                       \n",
       "5                                                  51.280932                                       \n",
       "\n",
       "           COMPLEXITY(recordings.settings_clusters.MAX(recordings.sensor_measurement_3))  \\\n",
       "engine_no                                                                                  \n",
       "1                                                2529.860061                               \n",
       "2                                                1194.615874                               \n",
       "3                                                1923.856686                               \n",
       "4                                                1062.343931                               \n",
       "5                                                1081.969011                               \n",
       "\n",
       "           LAST(recordings.settings_clusters.LAST(recordings.operational_setting_1))  \\\n",
       "engine_no                                                                              \n",
       "1                                                    41.9986                           \n",
       "2                                                     0.0004                           \n",
       "3                                                    24.9990                           \n",
       "4                                                    10.0028                           \n",
       "5                                                    25.0067                           \n",
       "\n",
       "           RUL  \n",
       "engine_no       \n",
       "1           32  \n",
       "2          230  \n",
       "3          169  \n",
       "4          238  \n",
       "5          144  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from featuretools.primitives import Last, Max\n",
    "from featuretools.primitives import make_agg_primitive\n",
    "import featuretools.variable_types as vtypes\n",
    "\n",
    "from tsfresh.feature_extraction.feature_calculators import (number_peaks, mean_abs_change, \n",
    "                                                            cid_ce, last_location_of_maximum, length)\n",
    "\n",
    "\n",
    "Complexity = make_agg_primitive(lambda x: cid_ce(x, False),\n",
    "                              input_types=[vtypes.Numeric],\n",
    "                              return_type=vtypes.Numeric,\n",
    "                              name=\"complexity\")\n",
    "\n",
    "fm, features = ft.dfs(entityset=es, \n",
    "                      target_entity='engines',\n",
    "                      agg_primitives=[Last, Max, Complexity],\n",
    "                      trans_primitives=[],\n",
    "                      chunk_size=.26,\n",
    "                      cutoff_time=cutoff_time_list[0],\n",
    "                      max_depth=3,\n",
    "                      verbose=True)\n",
    "\n",
    "fm.to_csv('advanced_fm.csv')\n",
    "fm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build 4 more feature matrices with the same feature set but different cutoff times. That lets us test the pipeline multiple times before using it on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [09:43<00:00, 145.90s/it]\n"
     ]
    }
   ],
   "source": [
    "fm_list = [fm]\n",
    "for i in tqdm(range(1, splits)):\n",
    "    fm = ft.calculate_feature_matrix(entityset=make_entityset(data, nclusters, kmeans=kmeans)[0], \n",
    "                                     features=features, \n",
    "                                     chunk_size=.26, \n",
    "                                     cutoff_time=cutoff_time_list[i])\n",
    "    fm_list.append(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43.0, 35.4, 31.0, 32.5, 34.8]\n",
      "Average MAE: 35.3, Std: 4.14\n",
      "\n",
      "1: COMPLEXITY(recordings.sensor_measurement_13) [0.053]\n",
      "2: COMPLEXITY(recordings.time_in_cycles) [0.037]\n",
      "3: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_11)) [0.036]\n",
      "4: COMPLEXITY(recordings.settings_clusters.LAST(recordings.sensor_measurement_13)) [0.036]\n",
      "5: MAX(recordings.sensor_measurement_11) [0.036]\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import RFE\n",
    "def pipeline_for_test(fm_list, hyperparams=[100, 50, 50], do_selection=False):\n",
    "    scores = []\n",
    "    regs = []\n",
    "    selectors = []\n",
    "    for fm in fm_list:\n",
    "        X = fm.copy().fillna(0)\n",
    "        y = X.pop('RUL')\n",
    "        reg = RandomForestRegressor(n_estimators=int(hyperparams[0]), \n",
    "                                    max_features=min(int(hyperparams[1]), \n",
    "                                                     int(hyperparams[2])))\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        if do_selection:\n",
    "            reg2 = RandomForestRegressor(n_jobs=3)\n",
    "            selector = RFE(reg2, int(hyperparams[2]), step=25)\n",
    "            selector.fit(X_train, y_train)\n",
    "            X_train = selector.transform(X_train)\n",
    "            X_test = selector.transform(X_test)\n",
    "            selectors.append(selector)\n",
    "        reg.fit(X_train, y_train)\n",
    "        regs.append(reg)\n",
    "        \n",
    "        preds = reg.predict(X_test)\n",
    "        scores.append(mean_absolute_error(preds, y_test))\n",
    "    return scores, regs, selectors    \n",
    "scores, regs, selectors = pipeline_for_test(fm_list)\n",
    "print([float('{:.1f}'.format(score)) for score in scores])\n",
    "print('Average MAE: {:.1f}, Std: {:.2f}\\n'.format(np.mean(scores), np.std(scores)))\n",
    "\n",
    "most_imp_feats = utils.feature_importances(fm_list[0], regs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with:\n",
      "41214 Recordings\n",
      "248 Engines\n",
      "21 Sensor Measurements\n",
      "3 Operational Settings\n",
      "Elapsed: 00:04 | Remaining: 00:00 | Progress: 100%|██████████| Calculated: 1/1 chunks\n",
      "Mean Abs Error: 32.38\n"
     ]
    }
   ],
   "source": [
    "data_test = utils.load_data('data/test_FD004.txt')\n",
    "\n",
    "es_test, _ = make_entityset(data_test, nclusters, kmeans=kmeans)\n",
    "fm_test = ft.calculate_feature_matrix(entityset=es_test, features=features, verbose=True, chunk_size='cutoff time')\n",
    "X = fm_test.copy().fillna(0)\n",
    "y = pd.read_csv('data/RUL_FD004.txt', sep=' ', header=-1, names=['RUL'], index_col=False)\n",
    "preds = regs[0].predict(X)\n",
    "print('Mean Abs Error: {:.2f}'.format(mean_absolute_error(preds, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Feature Selection and Scoring\n",
    "Here, we'll use [Recursive Feature Elimination](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html). In order to set ourselves up for later optimization, we're going to write a generic `pipeline` function which takes in a set of hyperparameters and returns a score. Our pipeline will first run `RFE` and then split the remaining data for scoring by a `RandomForestRegressor`. We're going to pass in a list of hyperparameters, which we will tune later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can use that selector and regressor to score the test values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Hyperparameter Tuning\n",
    "Because of the way we set up our pipeline, we can use a Gaussian Process to tune the hyperparameters. We will use [BTB](https://github.com/HDI-Project/BTB) from the [HDI Project](https://github.com/HDI-Project). This will search through the hyperparameters `n_estimators` and `max_feats` for RandomForest, and the number of features for RFE to find the hyperparameter set that has the best average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n_est, max_feats, nfeats]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 1/30 [00:17<08:23, 17.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. [79.0, 32.0, 64.0] -- Average MAE: 33.0, Std: 3.24\n",
      "Raw: [35.7, 36.0, 31.9, 34.3, 27.2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [05:52<02:56, 17.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19. [81.0, 27.0, 48.0] -- Average MAE: 31.1, Std: 1.02\n",
      "Raw: [29.7, 30.7, 31.5, 32.8, 31.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [08:43<00:00, 17.45s/it]\n"
     ]
    }
   ],
   "source": [
    "from btb.hyper_parameter import HyperParameter\n",
    "from btb.tuning import GP\n",
    "\n",
    "def run_btb(fm_list, n=30):\n",
    "    hyperparam_ranges = [\n",
    "            ('n_estimators', HyperParameter('int', [10, 200])),\n",
    "            ('max_feats', HyperParameter('int', [5, 50])),\n",
    "            ('nfeats', HyperParameter('int', [10, 70])),\n",
    "    ]\n",
    "    tuner = GP(hyperparam_ranges)\n",
    "\n",
    "    tested_parameters = np.zeros((n, len(hyperparam_ranges)), dtype=object)\n",
    "    scores = []\n",
    "    \n",
    "    print('[n_est, max_feats, nfeats]')\n",
    "    best = 45\n",
    "\n",
    "    for i in tqdm(range(n)):\n",
    "        tuner.fit(tested_parameters[:i, :], scores)\n",
    "        hyperparams = tuner.propose()\n",
    "        cvscores, regs, selectors = pipeline_for_test(fm_list, hyperparams=hyperparams, do_selection=True)\n",
    "        bound = np.mean(cvscores)\n",
    "        tested_parameters[i, :] = hyperparams\n",
    "        scores.append(-np.mean(cvscores))\n",
    "        if np.mean(cvscores) + np.std(cvscores) < best:\n",
    "            best = np.mean(cvscores)\n",
    "            best_hyperparams = [name for name in hyperparams]\n",
    "            best_reg = regs[0]\n",
    "            best_sel = selectors[0]\n",
    "            print('{}. {} -- Average MAE: {:.1f}, Std: {:.2f}'.format(i, \n",
    "                                                                      best_hyperparams, \n",
    "                                                                      np.mean(cvscores), \n",
    "                                                                      np.std(cvscores)))\n",
    "            print('Raw: {}'.format([float('{:.1f}'.format(s)) for s in cvscores]))\n",
    "\n",
    "    return best_hyperparams, (best_sel, best_reg)\n",
    "\n",
    "best_hyperparams, best_pipeline = run_btb(fm_list, n=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Abs Error on Test: 28.60\n",
      "1: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_13)) [0.072]\n",
      "2: COMPLEXITY(recordings.settings_clusters.MAX(recordings.sensor_measurement_14)) [0.067]\n",
      "3: COMPLEXITY(recordings.settings_clusters.MAX(recordings.sensor_measurement_16)) [0.065]\n",
      "4: COMPLEXITY(recordings.settings_clusters.LAST(recordings.time_in_cycles)) [0.060]\n",
      "5: MAX(recordings.sensor_measurement_11) [0.053]\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = fm_test.copy().fillna(0)\n",
    "y = pd.read_csv('data/RUL_FD004.txt', sep=' ', header=-1, names=['RUL'], index_col=False)\n",
    "\n",
    "preds = best_pipeline[1].predict(best_pipeline[0].transform(X))\n",
    "score = mean_absolute_error(preds, y)\n",
    "print('Mean Abs Error on Test: {:.2f}'.format(score))\n",
    "most_imp_feats = utils.feature_importances(X.iloc[:, best_pipeline[0].support_], best_pipeline[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Averaging old scores\n",
    "To make a fair comparison between the previous notebook and this one, we should average scores where possible. The work in this section is exactly the work in the previous notebook plus some code for taking the average in the validation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.1, 44.2, 35.0, 45.3, 36.4]\n",
      "Average MAE: 38.41, Std: 5.49\n",
      "\n",
      "[62.7, 69.2, 62.0, 73.6, 61.5]\n",
      "Baseline by Median MAE: 65.81, Std: 4.81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from featuretools.primitives import Min\n",
    "old_fm, features = ft.dfs(entityset=es, \n",
    "                      target_entity='engines',\n",
    "                      agg_primitives=[Last, Max, Min],\n",
    "                      trans_primitives=[],\n",
    "                      cutoff_time=cutoff_time_list[0],\n",
    "                      max_depth=3,\n",
    "                      verbose=True)\n",
    "\n",
    "old_fm_list = [old_fm]\n",
    "for i in tqdm(range(1, splits)):\n",
    "    old_fm = ft.calculate_feature_matrix(entityset=make_entityset(data, nclusters, kmeans=kmeans)[0], \n",
    "                                     features=features, \n",
    "                                     cutoff_time=cutoff_time_list[i])\n",
    "    old_fm_list.append(fm)\n",
    "\n",
    "old_scores = []\n",
    "median_scores = []\n",
    "for fm in old_fm_list:\n",
    "    X = fm.copy().fillna(0)\n",
    "    y = X.pop('RUL')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    reg = RandomForestRegressor()\n",
    "    reg.fit(X_train, y_train)\n",
    "    preds = reg.predict(X_test)\n",
    "    old_scores.append(mean_absolute_error(preds, y_test))\n",
    "    \n",
    "    medianpredict = [np.median(y_train) for _ in y_test]\n",
    "    median_scores.append(mean_absolute_error(medianpredict, y_test))\n",
    "\n",
    "print([float('{:.1f}'.format(score)) for score in old_scores])\n",
    "print('Average MAE: {:.2f}, Std: {:.2f}\\n'.format(np.mean(old_scores), np.std(old_scores)))\n",
    "\n",
    "print([float('{:.1f}'.format(score)) for score in median_scores])\n",
    "print('Baseline by Median MAE: {:.2f}, Std: {:.2f}\\n'.format(np.mean(median_scores), np.std(median_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49.5, 49.5, 52.8, 52.5, 50.4]\n",
      "Baseline by Median MAE: 50.93, Std: 1.45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv('data/RUL_FD004.txt', sep=' ', header=-1, names=['RUL'], index_col=False)\n",
    "median_scores_2 = []\n",
    "for ct in cutoff_time_list:\n",
    "    medianpredict2 = [np.median(ct['RUL'].values) for _ in y.values]\n",
    "    median_scores_2.append(mean_absolute_error(medianpredict2, y))\n",
    "print([float('{:.1f}'.format(score)) for score in median_scores_2])\n",
    "print('Baseline by Median MAE: {:.2f}, Std: {:.2f}\\n'.format(np.mean(median_scores_2), np.std(median_scores_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
